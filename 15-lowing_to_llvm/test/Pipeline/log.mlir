Args: /home/lfr/MLIR_Tutorial/build/15-lowing_to_llvm/src/Tools/NS-opt/NS-opt15 /home/lfr/MLIR_Tutorial/15-lowing_to_llvm/test/Pipeline/to_llvm_pipeline.mlir --north-star-basic-pipeline=DP_Nums=2 --mlir-print-ir-after-all --debug 
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemRefLayoutAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ElementsAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistinctAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ResourceBlobManagerDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineBinaryOpExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineConstantExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineDimExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineMapStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::IntegerSetStorage)
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableTypeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroOperands<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroOperands]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneRegion<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneRegion]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroResults<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroResults]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroSuccessors<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroSuccessors]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoRegionArguments<mlir::TypeID::get() [with Trait = mlir::OpTrait::NoRegionArguments]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoTerminator<mlir::TypeID::get() [with Trait = mlir::OpTrait::NoTerminator]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlock<mlir::TypeID::get() [with Trait = mlir::OpTrait::SingleBlock]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OpInvariants<mlir::TypeID::get() [with Trait = mlir::OpTrait::OpInvariants]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::BytecodeOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AffineScope<mlir::TypeID::get() [with Trait = mlir::OpTrait::AffineScope]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID::get() [with Trait = mlir::OpTrait::IsIsolatedFromAbove]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SymbolTable<mlir::TypeID::get() [with Trait = mlir::OpTrait::SymbolTable]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::SymbolOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::OpAsmOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface::Trait<mlir::TypeID::get() [with Trait = mlir::RegionKindInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasOnlyGraphRegion<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasOnlyGraphRegion]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::ModuleOpGenericAdaptorBase::Properties)
Load new dialect in Context func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectInlinerInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConvertToLLVMPatternInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface)
Load new dialect in Context cf
Load new dialect in Context arith
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferDeallocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueBoundsOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferViewFlowOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::mesh::ShardingInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AutomaticAllocationScope<mlir::TypeID::get() [with Trait = mlir::OpTrait::AutomaticAllocationScope]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::CallableOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::FunctionOpInterface::Trait]::Empty>)
Load new dialect in Context north_star
Load new dialect in Context tensor
Load new dialect in Context affine
Load new dialect in Context ub
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ub::PoisonAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineMapAccessInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaStartOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaWaitOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineReadOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineWriteOpInterface)
Load new dialect in Context complex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedDimOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OffsetSizeAndStrideOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::transform::FindPayloadReplacementOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetInsertionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetExtractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface)
Load new dialect in Context linalg
Load new dialect in Context math
Load new dialect in Context memref
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CopyOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableMemOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAccessorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableAllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ViewLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::AllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RuntimeVerifiableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::AggregatedOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::LinalgOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ContractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ConvolutionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::FillOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PartialReductionOpInterface)
Load new dialect in Context scf
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ParallelCombiningOpInterface)
Ignoring repeated interface registration
Ignoring repeated interface registration
Ignoring repeated interface registration
Load new dialect in Context index
Ignoring repeated interface registration
Ignoring repeated interface registration
Ignoring repeated interface registration
Ignoring repeated interface registration
Ignoring repeated interface registration
Ignoring repeated interface registration
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataParallelAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SupportedDataParallelismOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FusionRegionOpInterfaces)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroRegions<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroRegions]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicOperands<mlir::TypeID::get() [with Trait = mlir::OpTrait::VariadicOperands]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable::Trait<mlir::TypeID::get() [with Trait = mlir::ConditionallySpeculatable::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID::get() [with Trait = mlir::OpTrait::AlwaysSpeculatableImplTrait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::MemoryEffectOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::MemRefsNormalizable<mlir::TypeID::get() [with Trait = mlir::OpTrait::MemRefsNormalizable]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::RegionBranchTerminatorOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ReturnLike<mlir::TypeID::get() [with Trait = mlir::OpTrait::ReturnLike]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsTerminator<mlir::TypeID::get() [with Trait = mlir::OpTrait::IsTerminator]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutSpecInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneResult<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneResult]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneTypedResult<mlir::Type>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneOperand<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneOperand]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelOp::Trait<mlir::TypeID::get() [with Trait = mlir::DistributeParallelOp::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SupportedDataParallelismOp::Trait<mlir::TypeID::get() [with Trait = mlir::SupportedDataParallelismOp::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::OpToOpPassAdaptor)
run in MarkDistributeParallelParametersPass
root op: builtin.module
DPNums: 2
TPNums: 1
EPNums: 0
run out: MarkDistributeParallelParametersPass
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::PreservedAnalyses::AllAnalysesType)
// -----// IR Dump After MarkDistributeParallelParametersPass (mark-distribute-parallel-parameters) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.softmax"(%arg0) <{axis = 1 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>
    %1 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %1 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in ApplyDistributeTransformPass
root op: func.func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::BufferCastOpGenericAdaptorBase::Properties)
Apply DataParallelism to north_star.softmax
Apply DataParallelism to north_star.softmax
run out: ApplyDistributeTransformPass
// -----// IR Dump After ApplyDistributeTransformPass (apply-distribute-transform) //----- //
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  %4:2 = "north_star.buffer_cast"(%3) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %5 = "north_star.softmax"(%4#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = "north_star.softmax"(%4#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %7 = "north_star.buffer_cast"(%5, %6) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}

ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicResults<mlir::TypeID::get() [with Trait = mlir::OpTrait::VariadicResults]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectFoldInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ConstantLike<mlir::TypeID::get() [with Trait = mlir::OpTrait::ConstantLike]::Empty>)

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5e2dc3b59220) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6bac0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b5bfb0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b6b4f0) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6bb60) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6c4e0) {
  %4:2 = "north_star.buffer_cast"(%3) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
    ** Modified: 'north_star.softmax'(0x5e2dc3b58270)
    ** Modified: 'north_star.softmax'(0x5e2dc3b6c440)
    ** Erase   : 'north_star.buffer_cast'(0x5e2dc3b6c4e0)
    ** Erase   : 'north_star.buffer_cast'(0x5e2dc3b6bb60)
"mlir::north_star::{anonymous}::BufferCastOpFold" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %5 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b6b4f0) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b5bfb0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5e2dc3b59220) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b58270) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b6c440) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6c580) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasRecursiveMemoryEffects<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasRecursiveMemoryEffects]::Empty>)

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5e2dc3b59220) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6bac0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b5bfb0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b6b4f0) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b58270) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b6c440) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6c580) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
    %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
    return %5 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in DeviceRegionFusionPass
root op: func.func

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6c580) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b6c440) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b58270) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b6b4f0) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b5bfb0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6bac0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::DeviceKernelOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.device_kernel'(0x5e2dc3b6c4d0)
    ** Insert  : 'north_star.return'(0x5e2dc3af9b70)
    ** Modified: 'north_star.buffer_cast'(0x5e2dc3b6c580)
    ** Insert  : 'north_star.device_kernel'(0x5e2dc3b739b0)
    ** Insert  : 'north_star.return'(0x5e2dc3afa0f0)
    ** Modified: 'north_star.buffer_cast'(0x5e2dc3b6c580)
"{anonymous}::BufferCastOpDeviceRegionFusion" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FusionRegionOpInterfaces::Trait<mlir::TypeID::get() [with Trait = mlir::FusionRegionOpInterfaces::Trait]::Empty>)
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::north_star::DeviceKernelOp>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasParent<mlir::north_star::DeviceKernelOp>::Impl]::Empty>)
    %8 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %9 = "north_star.softmax"(%8) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %9 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %8 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = "north_star.softmax"(%8) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %9 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.softmax"(%3) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %7 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5e2dc3afa0f0) {
  "north_star.return"(%9) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b739b0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6c580) {
  %7 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5e2dc3af9b70) {
  "north_star.return"(%11) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b6c4d0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//
** Erase   : 'north_star.softmax'(0x5e2dc3b6c440)
** Erase   : 'north_star.softmax'(0x5e2dc3b58270)
** Erase   : 'north_star.softmax'(0x5e2dc3b6b4f0)
** Erase   : 'north_star.softmax'(0x5e2dc3b5bfb0)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%3) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6c580) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5e2dc3afa0f0) {
  "north_star.return"(%5) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b73b40) {
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b739b0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b73ab0) {
  %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5e2dc3af9b70) {
  "north_star.return"(%7) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b738d0) {
  %7 = "north_star.softmax"(%6) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b6c4d0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b58770) {
  %6 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6bac0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//
region has changed: true
run out: DeviceRegionFusionPass
// -----// IR Dump After DeviceRegionFusionPass (device-region-fusion) //----- //
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %5 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %5 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %3 : !north_star.ns_tensor<2x128xf32,0>
}

run in EliminateBufferCastPass

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%3) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6c580) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpToCommunicationPattern : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpToCommunicationPattern"
    ** Insert  : 'north_star.buffer'(0x5e2dc3b74990)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::ReifyRankedShapedTypeOpInterface::Trait]::Empty>)
    ** Insert  : 'tensor.empty'(0x5e2dc3b73bd0)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::TensorToNSTensorOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b5bfb0)
    ** Insert  : 'north_star.buffer'(0x5e2dc3b6b4f0)
    ** Insert  : 'north_star.gather'(0x5e2dc3b61a60)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::GetTensorOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.get_tensor'(0x5e2dc3b58270)
    ** Replace : 'north_star.buffer_cast'(0x5e2dc3b6c580)
    ** Modified: 'func.return'(0x5e2dc3b58d90)
"{anonymous}::BufferCastOpToCommunicationPattern" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %10 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %10 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer"(%1, %2) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %4 = tensor.empty() : tensor<2x128xf32>
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %6 = "north_star.buffer"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%3, %6) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  %8 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%7) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5e2dc3b58270) {
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.gather'(0x5e2dc3b61a60) {
  "north_star.gather"(%3, %6) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<2>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::NOperands<2>::Impl]::Empty>)
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5e2dc3b6b4f0) {
  %6 = "north_star.buffer"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b5bfb0) {
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5e2dc3b73bd0) {
  %4 = "tensor.empty"() : () -> tensor<2x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5e2dc3b74990) {
  %3 = "north_star.buffer"(%1, %2) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5e2dc3afa0f0) {
  "north_star.return"(%10) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b73b40) {
  %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b739b0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b73ab0) {
  %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5e2dc3af9b70) {
  "north_star.return"(%12) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b738d0) {
  %12 = "north_star.softmax"(%11) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b6c4d0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b58770) {
  %11 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5e2dc3b59220) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5e2dc3b6bac0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpToCommunicationPattern : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpToCommunicationPattern"
    ** Insert  : 'north_star.buffer'(0x5e2dc3b6c440)
    ** Insert  : 'tensor.empty'(0x5e2dc3b61b30)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b73c40)
    ** Insert  : 'tensor.empty'(0x5e2dc3b71300)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b71370)
    ** Insert  : 'north_star.buffer'(0x5e2dc3b71400)
    ** Insert  : 'north_star.scatter'(0x5e2dc3b714a0)
    ** Insert  : 'north_star.get_tensor'(0x5e2dc3b71550)
    ** Insert  : 'north_star.get_tensor'(0x5e2dc3b715e0)
    ** Replace : 'north_star.buffer_cast'(0x5e2dc3b6bac0)
    ** Modified: 'north_star.device_kernel'(0x5e2dc3b6c4d0)
    ** Modified: 'north_star.device_kernel'(0x5e2dc3b739b0)
"{anonymous}::BufferCastOpToCommunicationPattern" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = tensor.empty() : tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = tensor.empty() : tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %8:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %9 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %17 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %18 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %10 = "north_star.device_kernel"(%7) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %17 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %18 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %11 = "north_star.buffer"(%9, %10) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %12 = tensor.empty() : tensor<2x128xf32>
  %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %14 = "north_star.buffer"(%13) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%11, %14) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %15 = "north_star.get_tensor"(%14) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  %16 = "north_star.buffer_cast"(%9, %10) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %15 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b739b0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b6c4d0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5e2dc3b715e0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5e2dc3b71550) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.scatter'(0x5e2dc3b714a0) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5e2dc3b71400) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b71370) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5e2dc3b71300) {
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b73c40) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5e2dc3b61b30) {
  %1 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5e2dc3b59220) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5e2dc3b6c440) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//
** Erase   : 'north_star.buffer_cast'(0x5e2dc3b6c580)
** Erase   : 'north_star.buffer_cast'(0x5e2dc3b6bac0)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%14) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5e2dc3b58270) {
  %14 = "north_star.get_tensor"(%13) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.gather'(0x5e2dc3b61a60) {
  "north_star.gather"(%10, %13) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5e2dc3b6b4f0) {
  %13 = "north_star.buffer"(%12) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b5bfb0) {
  %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5e2dc3b73bd0) {
  %11 = "tensor.empty"() : () -> tensor<2x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5e2dc3b74990) {
  %10 = "north_star.buffer"(%8, %9) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5e2dc3afa0f0) {
  "north_star.return"(%16) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b73b40) {
  %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b739b0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b73ab0) {
  %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5e2dc3af9b70) {
  "north_star.return"(%18) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b738d0) {
  %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5e2dc3b6c4d0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5e2dc3b58770) {
  %17 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5e2dc3b715e0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5e2dc3b71550) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.scatter'(0x5e2dc3b714a0) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5e2dc3b71400) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b71370) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5e2dc3b71300) {
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b73c40) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5e2dc3b61b30) {
  %1 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5e2dc3b59220) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5e2dc3b6c440) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//
run out: EliminateBufferCastPass
// -----// IR Dump After EliminateBufferCastPass (eliminate-buffercast) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %8 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
    ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
      %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
      %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
      north_star.return %16 : !north_star.ns_tensor<1x128xf32,0>
    }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %9 = "north_star.device_kernel"(%7) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
    ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
      %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
      %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
      north_star.return %16 : !north_star.ns_tensor<1x128xf32,1>
    }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.buffer"(%8, %9) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %11 = tensor.empty() : tensor<2x128xf32>
    %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %13 = "north_star.buffer"(%12) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%10, %13) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %14 = "north_star.get_tensor"(%13) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %14 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in ConvertNorthStarToLinalgPass

//===-------------------------------------------===//
Legalizing operation : 'builtin.module'(0x5e2dc3b14150) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.func'(0x5e2dc3b59220) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5e2dc3b6c440) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b61b30) {
  %1 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b73c40) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b71300) {
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b71370) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5e2dc3b71400) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.scatter'(0x5e2dc3b714a0) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b71550) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b715e0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x5e2dc3b6c4d0) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpConvertPattern"
    ** Insert  : 'north_star.device_kernel'(0x5e2dc3b6bab0)
    ** Insert Block into : 'north_star.device_kernel'(0x5e2dc3b6bab0)
    ** Insert  : 'north_star.softmax'(0x5e2dc3b74790)
    ** Insert  : 'north_star.softmax'(0x5e2dc3b74800)
    ** Insert  : 'north_star.return'(0x5e2dc3b74860)
    ** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b76400)
    ** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b76530)
    ** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b765f0)
    ** Replace : 'north_star.device_kernel'(0x5e2dc3b6c4d0)
"{anonymous}::DeviceKernelOpConvertPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5e2dc3b74790) {
      %23 = "north_star.softmax"(%22) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x5e2dc3b79610)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::detail::SoftmaxOpGenericAdaptorBase::Properties)
        ** Insert  : 'linalg.softmax'(0x5e2dc3b79680)
        ** Replace : 'north_star.softmax'(0x5e2dc3b74790)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5e2dc3b79610) {
          %24 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5e2dc3b79680) {
          %25 = "linalg.softmax"(%23, %24) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = builtin.unrealized_conversion_cast %arg0 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  %2 = tensor.empty() : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = builtin.unrealized_conversion_cast %5 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  north_star.return %6 : tensor<1x128xf32>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.buffer'(0x5e2dc3b74990) {
      %13 = "north_star.buffer"(%10, %12) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.device_kernel'(0x5e2dc3b6bab0) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5e2dc3b74790) {
      %26 = "north_star.softmax"(%22) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked 'ignored' during conversion
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5e2dc3b74800) {
      %27 = "north_star.softmax"(%26) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x5e2dc3b764c0)
        ** Insert  : 'linalg.softmax'(0x5e2dc3b79860)
        ** Replace : 'north_star.softmax'(0x5e2dc3b74800)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5e2dc3b764c0) {
          %27 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5e2dc3b79860) {
          %28 = "linalg.softmax"(%25, %27) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = builtin.unrealized_conversion_cast %arg0 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  %2 = tensor.empty() : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %5 = tensor.empty() : tensor<1x128xf32>
  %6 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%5 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %7 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %8 = builtin.unrealized_conversion_cast %7 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  north_star.return %8 : tensor<1x128xf32>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x5e2dc3b74860) {
      "north_star.return"(%30) : (tensor<1x128xf32>) -> ()

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b76400) {
      %22 = "builtin.unrealized_conversion_cast"(%arg3) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b76530) {
      %30 = "builtin.unrealized_conversion_cast"(%29) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b765f0) {
      %10 = "builtin.unrealized_conversion_cast"(%9) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = tensor.empty() : tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = tensor.empty() : tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = builtin.unrealized_conversion_cast %6 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %9 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %18 = builtin.unrealized_conversion_cast %arg1 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
    %19 = builtin.unrealized_conversion_cast %18 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
    %20 = tensor.empty() : tensor<1x128xf32>
    %21 = linalg.softmax dimension(1) ins(%19 : tensor<1x128xf32>) outs(%20 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %22 = "north_star.softmax"(%18) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %23 = tensor.empty() : tensor<1x128xf32>
    %24 = linalg.softmax dimension(1) ins(%21 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = "north_star.softmax"(%22) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %26 = builtin.unrealized_conversion_cast %25 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
    north_star.return %26 : tensor<1x128xf32>
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %10 = builtin.unrealized_conversion_cast %9 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
  %11 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %18 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %19 = "north_star.softmax"(%18) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %19 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %12 = "north_star.device_kernel"(%8) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %18 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %19 = "north_star.softmax"(%18) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %19 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %13 = "north_star.buffer"(%10, %12) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %14 = tensor.empty() : tensor<2x128xf32>
  %15 = "north_star.tensor_to_ns_tensor"(%14) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %16 = "north_star.buffer"(%15) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%13, %16) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %17 = "north_star.get_tensor"(%16) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  return %17 : !north_star.ns_tensor<2x128xf32,0>
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x5e2dc3b58770) {
  %20 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x5e2dc3b738d0) {
  %21 = "north_star.softmax"(%20) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x5e2dc3af9b70) {
  "north_star.return"(%21) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x5e2dc3b739b0) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpConvertPattern"
    ** Insert  : 'north_star.device_kernel'(0x5e2dc3b79420)
    ** Insert Block into : 'north_star.device_kernel'(0x5e2dc3b79420)
    ** Insert  : 'north_star.softmax'(0x5e2dc3b767c0)
    ** Insert  : 'north_star.softmax'(0x5e2dc3b76830)
    ** Insert  : 'north_star.return'(0x5e2dc3b76890)
    ** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b76d10)
    ** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b76e90)
    ** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b3abf0)
    ** Replace : 'north_star.device_kernel'(0x5e2dc3b739b0)
"{anonymous}::DeviceKernelOpConvertPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5e2dc3b767c0) {
      %24 = "north_star.softmax"(%23) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x5e2dc3b78fc0)
        ** Insert  : 'linalg.softmax'(0x5e2dc3b79030)
        ** Replace : 'north_star.softmax'(0x5e2dc3b767c0)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5e2dc3b78fc0) {
          %25 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5e2dc3b79030) {
          %26 = "linalg.softmax"(%24, %25) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = builtin.unrealized_conversion_cast %arg0 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,1>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  %2 = tensor.empty() : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %6 = builtin.unrealized_conversion_cast %5 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  north_star.return %6 : tensor<1x128xf32>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.buffer'(0x5e2dc3b74990) {
      %16 = "north_star.buffer"(%11, %14) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.device_kernel'(0x5e2dc3b79420) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5e2dc3b767c0) {
      %27 = "north_star.softmax"(%23) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked 'ignored' during conversion
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5e2dc3b76830) {
      %28 = "north_star.softmax"(%27) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x5e2dc3b79170)
        ** Insert  : 'linalg.softmax'(0x5e2dc3b791e0)
        ** Replace : 'north_star.softmax'(0x5e2dc3b76830)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5e2dc3b79170) {
          %28 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5e2dc3b791e0) {
          %29 = "linalg.softmax"(%26, %28) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = builtin.unrealized_conversion_cast %arg0 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,1>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  %2 = tensor.empty() : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = tensor.empty() : tensor<1x128xf32>
  %6 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%5 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %7 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %8 = builtin.unrealized_conversion_cast %7 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  north_star.return %8 : tensor<1x128xf32>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x5e2dc3b76890) {
      "north_star.return"(%31) : (tensor<1x128xf32>) -> ()

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b76d10) {
      %23 = "builtin.unrealized_conversion_cast"(%arg2) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b76e90) {
      %31 = "builtin.unrealized_conversion_cast"(%30) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b3abf0) {
      %14 = "builtin.unrealized_conversion_cast"(%13) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = tensor.empty() : tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = tensor.empty() : tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = builtin.unrealized_conversion_cast %6 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %9 = builtin.unrealized_conversion_cast %8 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  %10 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %21 = builtin.unrealized_conversion_cast %arg1 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
    %22 = builtin.unrealized_conversion_cast %21 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
    %23 = tensor.empty() : tensor<1x128xf32>
    %24 = linalg.softmax dimension(1) ins(%22 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %26 = tensor.empty() : tensor<1x128xf32>
    %27 = linalg.softmax dimension(1) ins(%24 : tensor<1x128xf32>) outs(%26 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %28 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %29 = builtin.unrealized_conversion_cast %28 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
    north_star.return %29 : tensor<1x128xf32>
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %11 = builtin.unrealized_conversion_cast %10 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
  %12 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %21 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %22 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %22 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %13 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %21 = builtin.unrealized_conversion_cast %arg1 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,1>
    %22 = builtin.unrealized_conversion_cast %21 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
    %23 = tensor.empty() : tensor<1x128xf32>
    %24 = linalg.softmax dimension(1) ins(%22 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %26 = tensor.empty() : tensor<1x128xf32>
    %27 = linalg.softmax dimension(1) ins(%24 : tensor<1x128xf32>) outs(%26 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %28 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %29 = builtin.unrealized_conversion_cast %28 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
    north_star.return %29 : tensor<1x128xf32>
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %14 = builtin.unrealized_conversion_cast %13 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,1>
  %15 = "north_star.device_kernel"(%8) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %21 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %22 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %22 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %16 = "north_star.buffer"(%11, %14) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %17 = tensor.empty() : tensor<2x128xf32>
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %19 = "north_star.buffer"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%16, %19) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  return %20 : !north_star.ns_tensor<2x128xf32,0>
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x5e2dc3b73ab0) {
  %21 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x5e2dc3b73b40) {
  %22 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x5e2dc3afa0f0) {
  "north_star.return"(%22) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5e2dc3b74990) {
  %16 = "north_star.buffer"(%11, %14) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b73bd0) {
  %17 = "tensor.empty"() : () -> tensor<2x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b5bfb0) {
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5e2dc3b6b4f0) {
  %19 = "north_star.buffer"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.gather'(0x5e2dc3b61a60) {
  "north_star.gather"(%16, %19) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b58270) {
  %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%20) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//
** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b771b0)
** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b770f0)
** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b77240)
** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b77400)
run out: ConvertNorthStarToLinalgPass
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::DestinationStyleOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::AggregatedOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::linalg::AggregatedOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface::Trait<mlir::TypeID::get() [with Trait = mlir::TilingInterface::Trait]::Empty>)
// -----// IR Dump After ConvertNorthStarToLinalgPass (convert-north-satr-to-linalg) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = builtin.unrealized_conversion_cast %6 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
    %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = builtin.unrealized_conversion_cast %8 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
    %10 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %19 = builtin.unrealized_conversion_cast %arg1 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
      %20 = tensor.empty() : tensor<1x128xf32>
      %21 = linalg.softmax dimension(1) ins(%arg1 : tensor<1x128xf32>) outs(%20 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %22 = tensor.empty() : tensor<1x128xf32>
      %23 = linalg.softmax dimension(1) ins(%21 : tensor<1x128xf32>) outs(%22 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %24 = builtin.unrealized_conversion_cast %23 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
      %25 = builtin.unrealized_conversion_cast %24 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
      north_star.return %25 : tensor<1x128xf32>
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %11 = builtin.unrealized_conversion_cast %10 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
    %12 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %19 = builtin.unrealized_conversion_cast %arg1 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,1>
      %20 = tensor.empty() : tensor<1x128xf32>
      %21 = linalg.softmax dimension(1) ins(%arg1 : tensor<1x128xf32>) outs(%20 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %22 = tensor.empty() : tensor<1x128xf32>
      %23 = linalg.softmax dimension(1) ins(%21 : tensor<1x128xf32>) outs(%22 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %24 = builtin.unrealized_conversion_cast %23 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,1>
      %25 = builtin.unrealized_conversion_cast %24 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
      north_star.return %25 : tensor<1x128xf32>
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %13 = builtin.unrealized_conversion_cast %12 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,1>
    %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %15 = tensor.empty() : tensor<2x128xf32>
    %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %18 : !north_star.ns_tensor<2x128xf32,0>
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = builtin.unrealized_conversion_cast %6 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
    %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = builtin.unrealized_conversion_cast %8 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
    %10 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %19 = tensor.empty() : tensor<1x128xf32>
      %20 = linalg.softmax dimension(1) ins(%arg1 : tensor<1x128xf32>) outs(%19 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %21 = tensor.empty() : tensor<1x128xf32>
      %22 = linalg.softmax dimension(1) ins(%20 : tensor<1x128xf32>) outs(%21 : tensor<1x128xf32>) -> tensor<1x128xf32>
      north_star.return %22 : tensor<1x128xf32>
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %11 = builtin.unrealized_conversion_cast %10 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,0>
    %12 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %19 = tensor.empty() : tensor<1x128xf32>
      %20 = linalg.softmax dimension(1) ins(%arg1 : tensor<1x128xf32>) outs(%19 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %21 = tensor.empty() : tensor<1x128xf32>
      %22 = linalg.softmax dimension(1) ins(%20 : tensor<1x128xf32>) outs(%21 : tensor<1x128xf32>) -> tensor<1x128xf32>
      north_star.return %22 : tensor<1x128xf32>
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %13 = builtin.unrealized_conversion_cast %12 : tensor<1x128xf32> to !north_star.ns_tensor<1x128xf32,1>
    %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %15 = tensor.empty() : tensor<2x128xf32>
    %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %18 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in ConvertNorthStarToFuncPass

//===-------------------------------------------===//
Legalizing operation : 'builtin.module'(0x5e2dc3b14150) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.func'(0x5e2dc3b59220) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5e2dc3b6c440) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b61b30) {
  %1 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b73c40) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b71300) {
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b71370) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5e2dc3b71400) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.scatter'(0x5e2dc3b714a0) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b71550) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.get_tensor -> ()' {
Trying to match "{anonymous}::GetTensorOpRefineResultPattern"
    ** Insert  : 'north_star.get_tensor'(0x5e2dc3b73b40)
    ** Replace : 'north_star.get_tensor'(0x5e2dc3b71550)
"{anonymous}::GetTensorOpRefineResultPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b73b40) {
      %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
^bb0(%arg0: !north_star.ns_tensor<2x128xf32,0>):
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = "tensor.empty"() : () -> tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>
  %7 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %8 = "builtin.unrealized_conversion_cast"(%7) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %9 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %10 = "builtin.unrealized_conversion_cast"(%9) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %11 = "north_star.device_kernel"(%8) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg2: tensor<1x128xf32>):
    %24 = "tensor.empty"() : () -> tensor<1x128xf32>
    %25 = "linalg.softmax"(%arg2, %24) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %26 = "tensor.empty"() : () -> tensor<1x128xf32>
    %27 = "linalg.softmax"(%25, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%27) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %12 = "builtin.unrealized_conversion_cast"(%11) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %13 = "north_star.device_kernel"(%10) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %20 = "tensor.empty"() : () -> tensor<1x128xf32>
    %21 = "linalg.softmax"(%arg1, %20) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %22 = "tensor.empty"() : () -> tensor<1x128xf32>
    %23 = "linalg.softmax"(%21, %22) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%23) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %14 = "builtin.unrealized_conversion_cast"(%13) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %15 = "north_star.buffer"(%12, %14) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %16 = "tensor.empty"() : () -> tensor<2x128xf32>
  %17 = "north_star.tensor_to_ns_tensor"(%16) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %18 = "north_star.buffer"(%17) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%15, %18) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %19 = "north_star.get_tensor"(%18) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%19) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b770f0) {
  %8 = "builtin.unrealized_conversion_cast"(%7) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b715e0) {
  %9 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.get_tensor -> ()' {
Trying to match "{anonymous}::GetTensorOpRefineResultPattern"
    ** Insert  : 'north_star.get_tensor'(0x5e2dc3b76730)
    ** Replace : 'north_star.get_tensor'(0x5e2dc3b715e0)
"{anonymous}::GetTensorOpRefineResultPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b76730) {
      %9 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
^bb0(%arg0: !north_star.ns_tensor<2x128xf32,0>):
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = "tensor.empty"() : () -> tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>
  %7 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %8 = "builtin.unrealized_conversion_cast"(%7) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %9 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>
  %10 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %11 = "builtin.unrealized_conversion_cast"(%10) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %12 = "north_star.device_kernel"(%8) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg2: tensor<1x128xf32>):
    %25 = "tensor.empty"() : () -> tensor<1x128xf32>
    %26 = "linalg.softmax"(%arg2, %25) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %27 = "tensor.empty"() : () -> tensor<1x128xf32>
    %28 = "linalg.softmax"(%26, %27) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%28) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %13 = "builtin.unrealized_conversion_cast"(%12) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %14 = "north_star.device_kernel"(%11) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %21 = "tensor.empty"() : () -> tensor<1x128xf32>
    %22 = "linalg.softmax"(%arg1, %21) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %23 = "tensor.empty"() : () -> tensor<1x128xf32>
    %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%24) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %15 = "builtin.unrealized_conversion_cast"(%14) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %16 = "north_star.buffer"(%13, %15) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %17 = "tensor.empty"() : () -> tensor<2x128xf32>
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %19 = "north_star.buffer"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%16, %19) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%20) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b771b0) {
  %11 = "builtin.unrealized_conversion_cast"(%10) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x5e2dc3b6bab0) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b79610) {
  %25 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x5e2dc3b79680) {
  %26 = "linalg.softmax"(%arg2, %25) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b764c0) {
  %27 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x5e2dc3b79860) {
  %28 = "linalg.softmax"(%26, %27) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x5e2dc3b74860) {
  "north_star.return"(%28) : (tensor<1x128xf32>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b765f0) {
  %13 = "builtin.unrealized_conversion_cast"(%12) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x5e2dc3b79420) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b78fc0) {
  %21 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x5e2dc3b79030) {
  %22 = "linalg.softmax"(%arg1, %21) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b79170) {
  %23 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x5e2dc3b791e0) {
  %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x5e2dc3b76890) {
  "north_star.return"(%24) : (tensor<1x128xf32>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'builtin.unrealized_conversion_cast'(0x5e2dc3b3abf0) {
  %15 = "builtin.unrealized_conversion_cast"(%14) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5e2dc3b74990) {
  %16 = "north_star.buffer"(%13, %15) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5e2dc3b73bd0) {
  %17 = "tensor.empty"() : () -> tensor<2x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5e2dc3b5bfb0) {
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5e2dc3b6b4f0) {
  %19 = "north_star.buffer"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.gather'(0x5e2dc3b61a60) {
  "north_star.gather"(%16, %19) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b58270) {
  %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.get_tensor -> ()' {
Trying to match "{anonymous}::GetTensorOpRefineResultPattern"
    ** Insert  : 'north_star.get_tensor'(0x5e2dc3b762e0)
    ** Replace : 'north_star.get_tensor'(0x5e2dc3b58270)
"{anonymous}::GetTensorOpRefineResultPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.get_tensor'(0x5e2dc3b762e0) {
      %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> tensor<2x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
^bb0(%arg0: !north_star.ns_tensor<2x128xf32,0>):
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = "tensor.empty"() : () -> tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>
  %7 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %8 = "builtin.unrealized_conversion_cast"(%7) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %9 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>
  %10 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %11 = "builtin.unrealized_conversion_cast"(%10) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %12 = "north_star.device_kernel"(%8) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg2: tensor<1x128xf32>):
    %26 = "tensor.empty"() : () -> tensor<1x128xf32>
    %27 = "linalg.softmax"(%arg2, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %28 = "tensor.empty"() : () -> tensor<1x128xf32>
    %29 = "linalg.softmax"(%27, %28) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%29) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %13 = "builtin.unrealized_conversion_cast"(%12) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %14 = "north_star.device_kernel"(%11) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %22 = "tensor.empty"() : () -> tensor<1x128xf32>
    %23 = "linalg.softmax"(%arg1, %22) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %24 = "tensor.empty"() : () -> tensor<1x128xf32>
    %25 = "linalg.softmax"(%23, %24) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%25) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %15 = "builtin.unrealized_conversion_cast"(%14) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %16 = "north_star.buffer"(%13, %15) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %17 = "tensor.empty"() : () -> tensor<2x128xf32>
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %19 = "north_star.buffer"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%16, %19) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> tensor<2x128xf32>
  %21 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%21) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.return'(0x5e2dc3b58d90) {
  "func.return"(%21) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//
** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b79580)
** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b58770)
** Insert  : 'builtin.unrealized_conversion_cast'(0x5e2dc3b738d0)
run out: ConvertNorthStarToFuncPass
// -----// IR Dump After ConvertNorthStarToFuncPass Failed (convert-north-satr-to-func) //----- //
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
"builtin.module"() <{sym_name = "NorthStar"}> ({
  "func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
  ^bb0(%arg0: !north_star.ns_tensor<2x128xf32,0>):
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = "tensor.empty"() : () -> tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = "tensor.empty"() : () -> tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>
    %7 = "builtin.unrealized_conversion_cast"(%6) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %8 = "builtin.unrealized_conversion_cast"(%7) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %9 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> tensor<1x128xf32>
    %10 = "builtin.unrealized_conversion_cast"(%9) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %11 = "builtin.unrealized_conversion_cast"(%10) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %12 = "north_star.device_kernel"(%8) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
    ^bb0(%arg2: tensor<1x128xf32>):
      %26 = "tensor.empty"() : () -> tensor<1x128xf32>
      %27 = "linalg.softmax"(%arg2, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      %28 = "tensor.empty"() : () -> tensor<1x128xf32>
      %29 = "linalg.softmax"(%27, %28) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      "north_star.return"(%29) : (tensor<1x128xf32>) -> ()
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %13 = "builtin.unrealized_conversion_cast"(%12) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %14 = "north_star.device_kernel"(%11) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %22 = "tensor.empty"() : () -> tensor<1x128xf32>
      %23 = "linalg.softmax"(%arg1, %22) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      %24 = "tensor.empty"() : () -> tensor<1x128xf32>
      %25 = "linalg.softmax"(%23, %24) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      "north_star.return"(%25) : (tensor<1x128xf32>) -> ()
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %15 = "builtin.unrealized_conversion_cast"(%14) : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %16 = "north_star.buffer"(%13, %15) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %17 = "tensor.empty"() : () -> tensor<2x128xf32>
    %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %19 = "north_star.buffer"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%16, %19) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> tensor<2x128xf32>
    %21 = "builtin.unrealized_conversion_cast"(%20) : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    "func.return"(%21) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
  }) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()
}) : () -> ()


initializing north_star
register north_star  Type
register north_star  Attr
register north_star  Op
destroying north_star

Args: /home/lfr/MLIR_Tutorial/build/15-lowing_to_llvm/src/Tools/NS-opt/NS-opt15 /home/lfr/MLIR_Tutorial/15-lowing_to_llvm/test/Pipeline/to_llvm_pipeline.mlir --north-star-basic-pipeline=DP_Nums=2 --mlir-print-ir-after-all --debug 
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemRefLayoutAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ElementsAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistinctAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ResourceBlobManagerDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineBinaryOpExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineConstantExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineDimExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineMapStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::IntegerSetStorage)
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroOperands<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroOperands]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneRegion<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneRegion]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroResults<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroResults]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroSuccessors<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroSuccessors]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoRegionArguments<mlir::TypeID::get() [with Trait = mlir::OpTrait::NoRegionArguments]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoTerminator<mlir::TypeID::get() [with Trait = mlir::OpTrait::NoTerminator]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlock<mlir::TypeID::get() [with Trait = mlir::OpTrait::SingleBlock]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OpInvariants<mlir::TypeID::get() [with Trait = mlir::OpTrait::OpInvariants]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::BytecodeOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AffineScope<mlir::TypeID::get() [with Trait = mlir::OpTrait::AffineScope]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID::get() [with Trait = mlir::OpTrait::IsIsolatedFromAbove]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SymbolTable<mlir::TypeID::get() [with Trait = mlir::OpTrait::SymbolTable]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::SymbolOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::OpAsmOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface::Trait<mlir::TypeID::get() [with Trait = mlir::RegionKindInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasOnlyGraphRegion<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasOnlyGraphRegion]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::ModuleOpGenericAdaptorBase::Properties)
Load new dialect in Context func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectInlinerInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConvertToLLVMPatternInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AutomaticAllocationScope<mlir::TypeID::get() [with Trait = mlir::OpTrait::AutomaticAllocationScope]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::CallableOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::FunctionOpInterface::Trait]::Empty>)
Load new dialect in Context north_star
Load new dialect in Context tensor
Load new dialect in Context affine
Load new dialect in Context arith
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferDeallocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueBoundsOpInterface)
Load new dialect in Context ub
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ub::PoisonAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineMapAccessInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaStartOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaWaitOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineReadOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineWriteOpInterface)
Load new dialect in Context complex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedDimOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OffsetSizeAndStrideOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::transform::FindPayloadReplacementOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetInsertionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetExtractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataParallelAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SupportedDataParallelismOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FusionRegionOpInterfaces)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroRegions<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroRegions]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicOperands<mlir::TypeID::get() [with Trait = mlir::OpTrait::VariadicOperands]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable::Trait<mlir::TypeID::get() [with Trait = mlir::ConditionallySpeculatable::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID::get() [with Trait = mlir::OpTrait::AlwaysSpeculatableImplTrait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::MemoryEffectOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::MemRefsNormalizable<mlir::TypeID::get() [with Trait = mlir::OpTrait::MemRefsNormalizable]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::RegionBranchTerminatorOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ReturnLike<mlir::TypeID::get() [with Trait = mlir::OpTrait::ReturnLike]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsTerminator<mlir::TypeID::get() [with Trait = mlir::OpTrait::IsTerminator]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutSpecInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneResult<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneResult]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneTypedResult<mlir::Type>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneOperand<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneOperand]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelOp::Trait<mlir::TypeID::get() [with Trait = mlir::DistributeParallelOp::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SupportedDataParallelismOp::Trait<mlir::TypeID::get() [with Trait = mlir::SupportedDataParallelismOp::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::OpToOpPassAdaptor)
Load new dialect in Context linalg
Load new dialect in Context math
Load new dialect in Context memref
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CopyOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableMemOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAccessorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableAllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ViewLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::AllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RuntimeVerifiableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableTypeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::AggregatedOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::LinalgOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ContractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ConvolutionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::FillOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::mesh::ShardingInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PartialReductionOpInterface)
run in MarkDistributeParallelParametersPass
root op: builtin.module
DPNums: 2
TPNums: 1
EPNums: 0
run out: MarkDistributeParallelParametersPass
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::PreservedAnalyses::AllAnalysesType)
// -----// IR Dump After MarkDistributeParallelParametersPass (mark-distribute-parallel-parameters) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.softmax"(%arg0) <{axis = 1 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>
    %1 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %1 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in ApplyDistributeTransformPass
root op: func.func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::BufferCastOpGenericAdaptorBase::Properties)
Apply DataParallelism to north_star.softmax
Apply DataParallelism to north_star.softmax
run out: ApplyDistributeTransformPass
// -----// IR Dump After ApplyDistributeTransformPass (apply-distribute-transform) //----- //
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  %4:2 = "north_star.buffer_cast"(%3) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %5 = "north_star.softmax"(%4#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = "north_star.softmax"(%4#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %7 = "north_star.buffer_cast"(%5, %6) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}

ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicResults<mlir::TypeID::get() [with Trait = mlir::OpTrait::VariadicResults]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectFoldInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ConstantLike<mlir::TypeID::get() [with Trait = mlir::OpTrait::ConstantLike]::Empty>)

//===-------------------------------------------===//
Processing operation : 'func.func'(0x6204461b2bd0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f0cf0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461df7f0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f0720) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f0d90) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f1710) {
  %4:2 = "north_star.buffer_cast"(%3) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
    ** Modified: 'north_star.softmax'(0x6204461b1fb0)
    ** Modified: 'north_star.softmax'(0x6204461f1670)
    ** Erase   : 'north_star.buffer_cast'(0x6204461f1710)
    ** Erase   : 'north_star.buffer_cast'(0x6204461f0d90)
"mlir::north_star::{anonymous}::BufferCastOpFold" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %5 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f0720) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461df7f0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x6204461b2bd0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461b1fb0) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f1670) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f17b0) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasRecursiveMemoryEffects<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasRecursiveMemoryEffects]::Empty>)

//===-------------------------------------------===//
Processing operation : 'func.func'(0x6204461b2bd0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f0cf0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461df7f0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f0720) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461b1fb0) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f1670) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f17b0) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
    %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
    return %5 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in DeviceRegionFusionPass
root op: func.func

//===-------------------------------------------===//
Processing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f17b0) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f1670) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461b1fb0) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f0720) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461df7f0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f0cf0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::DeviceKernelOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.device_kernel'(0x6204461f1700)
    ** Insert  : 'north_star.return'(0x6204461f8aa0)
    ** Modified: 'north_star.buffer_cast'(0x6204461f17b0)
    ** Insert  : 'north_star.device_kernel'(0x6204461f8bb0)
    ** Insert  : 'north_star.return'(0x6204461f8dc0)
    ** Modified: 'north_star.buffer_cast'(0x6204461f17b0)
"{anonymous}::BufferCastOpDeviceRegionFusion" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FusionRegionOpInterfaces::Trait<mlir::TypeID::get() [with Trait = mlir::FusionRegionOpInterfaces::Trait]::Empty>)
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::north_star::DeviceKernelOp>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasParent<mlir::north_star::DeviceKernelOp>::Impl]::Empty>)
    %8 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %9 = "north_star.softmax"(%8) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %9 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %8 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = "north_star.softmax"(%8) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %9 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.softmax"(%3) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %7 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x6204461f8dc0) {
  "north_star.return"(%9) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f8bb0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f17b0) {
  %7 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x6204461f8aa0) {
  "north_star.return"(%11) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f1700) {
} -> failure : pattern failed to match
//===-------------------------------------------===//
** Erase   : 'north_star.softmax'(0x6204461f1670)
** Erase   : 'north_star.softmax'(0x6204461b1fb0)
** Erase   : 'north_star.softmax'(0x6204461f0720)
** Erase   : 'north_star.softmax'(0x6204461df7f0)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%3) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f17b0) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x6204461f8dc0) {
  "north_star.return"(%5) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f8d40) {
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f8bb0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f8cb0) {
  %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x6204461f8aa0) {
  "north_star.return"(%7) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f89e0) {
  %7 = "north_star.softmax"(%6) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f1700) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461b2510) {
  %6 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f0cf0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//
region has changed: true
run out: DeviceRegionFusionPass
// -----// IR Dump After DeviceRegionFusionPass (device-region-fusion) //----- //
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %5 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %5 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %3 : !north_star.ns_tensor<2x128xf32,0>
}

run in EliminateBufferCastPass

//===-------------------------------------------===//
Processing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%3) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f17b0) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpToCommunicationPattern : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpToCommunicationPattern"
    ** Insert  : 'north_star.buffer'(0x6204461e4d20)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::ReifyRankedShapedTypeOpInterface::Trait]::Empty>)
    ** Insert  : 'tensor.empty'(0x6204461f8e50)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::TensorToNSTensorOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x6204461df7f0)
    ** Insert  : 'north_star.buffer'(0x6204461f0720)
    ** Insert  : 'north_star.gather'(0x6204461e4ec0)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::GetTensorOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.get_tensor'(0x6204461b1fb0)
    ** Replace : 'north_star.buffer_cast'(0x6204461f17b0)
    ** Modified: 'func.return'(0x6204461b2b50)
"{anonymous}::BufferCastOpToCommunicationPattern" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %10 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %10 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer"(%1, %2) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %4 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %6 = "north_star.buffer"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%3, %6) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  %8 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%7) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x6204461b1fb0) {
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.gather'(0x6204461e4ec0) {
  "north_star.gather"(%3, %6) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<2>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::NOperands<2>::Impl]::Empty>)
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x6204461f0720) {
  %6 = "north_star.buffer"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x6204461df7f0) {
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x6204461f8e50) {
  %4 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x6204461e4d20) {
  %3 = "north_star.buffer"(%1, %2) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x6204461f8dc0) {
  "north_star.return"(%10) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f8d40) {
  %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f8bb0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f8cb0) {
  %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x6204461f8aa0) {
  "north_star.return"(%12) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f89e0) {
  %12 = "north_star.softmax"(%11) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f1700) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461b2510) {
  %11 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x6204461b2bd0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x6204461f0cf0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpToCommunicationPattern : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpToCommunicationPattern"
    ** Insert  : 'north_star.buffer'(0x6204461f1670)
    ** Insert  : 'tensor.empty'(0x6204461e4f90)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x6204461f8ec0)
    ** Insert  : 'tensor.empty'(0x6204461f97c0)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x6204461f9830)
    ** Insert  : 'north_star.buffer'(0x6204461f98c0)
    ** Insert  : 'north_star.scatter'(0x6204461f9960)
    ** Insert  : 'north_star.get_tensor'(0x6204461f9a10)
    ** Insert  : 'north_star.get_tensor'(0x6204461f9aa0)
    ** Replace : 'north_star.buffer_cast'(0x6204461f0cf0)
    ** Modified: 'north_star.device_kernel'(0x6204461f1700)
    ** Modified: 'north_star.device_kernel'(0x6204461f8bb0)
"{anonymous}::BufferCastOpToCommunicationPattern" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %8:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %9 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %17 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %18 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %10 = "north_star.device_kernel"(%7) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %17 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %18 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %11 = "north_star.buffer"(%9, %10) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %12 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
  %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %14 = "north_star.buffer"(%13) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%11, %14) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %15 = "north_star.get_tensor"(%14) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  %16 = "north_star.buffer_cast"(%9, %10) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %15 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f8bb0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f1700) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x6204461f9aa0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x6204461f9a10) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.scatter'(0x6204461f9960) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x6204461f98c0) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x6204461f9830) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x6204461f97c0) {
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x6204461f8ec0) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x6204461e4f90) {
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x6204461b2bd0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x6204461f1670) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//
** Erase   : 'north_star.buffer_cast'(0x6204461f17b0)
** Erase   : 'north_star.buffer_cast'(0x6204461f0cf0)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%14) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x6204461b1fb0) {
  %14 = "north_star.get_tensor"(%13) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.gather'(0x6204461e4ec0) {
  "north_star.gather"(%10, %13) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x6204461f0720) {
  %13 = "north_star.buffer"(%12) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x6204461df7f0) {
  %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x6204461f8e50) {
  %11 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x6204461e4d20) {
  %10 = "north_star.buffer"(%8, %9) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x6204461f8dc0) {
  "north_star.return"(%16) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f8d40) {
  %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f8bb0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f8cb0) {
  %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x6204461f8aa0) {
  "north_star.return"(%18) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461f89e0) {
  %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x6204461f1700) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x6204461b2510) {
  %17 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x6204461f9aa0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x6204461f9a10) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.scatter'(0x6204461f9960) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x6204461f98c0) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x6204461f9830) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x6204461f97c0) {
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x6204461f8ec0) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x6204461e4f90) {
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x6204461b2bd0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x6204461f1670) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//
run out: EliminateBufferCastPass
// -----// IR Dump After EliminateBufferCastPass (eliminate-buffercast) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %8 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
      %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
      %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
      north_star.return %16 : !north_star.ns_tensor<1x128xf32,0>
    }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %9 = "north_star.device_kernel"(%7) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
      %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
      %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
      north_star.return %16 : !north_star.ns_tensor<1x128xf32,1>
    }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.buffer"(%8, %9) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %11 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %13 = "north_star.buffer"(%12) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%10, %13) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %14 = "north_star.get_tensor"(%13) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %14 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in ConvertNorthStarToLinalgPass

//===-------------------------------------------===//
Legalizing operation : 'builtin.module'(0x6204461aef60) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.func'(0x6204461b2bd0) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x6204461f1670) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461e4f90) {
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461f8ec0) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461f97c0) {
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461f9830) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x6204461f98c0) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.scatter'(0x6204461f9960) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x6204461f9a10) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x6204461f9aa0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x6204461f1700) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpConvertPattern"
    ** Insert  : 'north_star.device_kernel'(0x6204461f0ce0)
    ** Insert Block into : 'north_star.device_kernel'(0x6204461f0ce0)
    ** Insert  : 'north_star.softmax'(0x6204461f6760)
    ** Insert  : 'north_star.softmax'(0x6204461f71f0)
    ** Insert  : 'north_star.return'(0x6204461f6200)
<block argument> of type '!north_star.ns_tensor<1x128xf32,0>' at index: 0
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x6204461fb780)
    ** Replace : 'north_star.device_kernel'(0x6204461f1700)
"{anonymous}::DeviceKernelOpConvertPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x6204461f6760) {
      %22 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x6204461fe7c0)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::detail::SoftmaxOpGenericAdaptorBase::Properties)
        ** Insert  : 'linalg.softmax'(0x6204461fe830)
        ** Replace : 'north_star.softmax'(0x6204461f6760)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x6204461fe7c0) {
          %23 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x6204461fe830) {
          %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  %2 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  north_star.return %5 : !north_star.ns_tensor<1x128xf32,0>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.device_kernel'(0x6204461f0ce0) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x6204461f6760) {
      %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked 'ignored' during conversion
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x6204461f71f0) {
      %26 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x6204461fe9b0)
        ** Insert  : 'linalg.softmax'(0x6204461fea20)
        ** Replace : 'north_star.softmax'(0x6204461f71f0)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x6204461fe9b0) {
          %26 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x6204461fea20) {
          %27 = "linalg.softmax"(%24, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  %2 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %5 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
  %6 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%5 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %7 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  north_star.return %7 : !north_star.ns_tensor<1x128xf32,0>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x6204461f6200) {
      "north_star.return"(%28) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.return -> ()' {
Trying to match "{anonymous}::ReturnOpConvertPattern"
        ** Insert  : 'north_star.return'(0x6204461f73a0)
        ** Replace : 'north_star.return'(0x6204461f6200)
"{anonymous}::ReturnOpConvertPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'north_star.return'(0x6204461f73a0) {
          "north_star.return"(%27) : (tensor<1x128xf32>) -> ()

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'north_star.return' op must be the last operation in the parent block
mlir-asm-printer: 'north_star.device_kernel' failed to verify and will be printed in generic form
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %1 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "builtin.unrealized_conversion_cast"(%1) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %3 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %4 = "linalg.softmax"(%2, %3) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %5 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %7 = "linalg.softmax"(%4, %6) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %8 = "north_star.softmax"(%5) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  "north_star.return"(%7) : (tensor<1x128xf32>) -> ()
  "north_star.return"(%8) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461fb780) {
      %21 = "north_star.tensor_to_ns_tensor"(%arg3) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'north_star.return' op must be the last operation in the parent block
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
^bb0(%arg0: !north_star.ns_tensor<2x128xf32,0>):
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "builtin.unrealized_conversion_cast"(%6) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %9 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg3: tensor<1x128xf32>):
    %21 = "north_star.tensor_to_ns_tensor"(%arg3) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %22 = "builtin.unrealized_conversion_cast"(%21) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %23 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
    %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %26 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
    %27 = "linalg.softmax"(%24, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %28 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    "north_star.return"(%27) : (tensor<1x128xf32>) -> ()
    "north_star.return"(%28) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %10 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg2: !north_star.ns_tensor<1x128xf32,0>):
    %19 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %20 = "north_star.softmax"(%19) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    "north_star.return"(%20) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %11 = "north_star.device_kernel"(%8) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %17 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    "north_star.return"(%18) : (!north_star.ns_tensor<1x128xf32,1>) -> ()
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %12 = "north_star.buffer"(%10, %11) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %13 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
  %14 = "north_star.tensor_to_ns_tensor"(%13) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %15 = "north_star.buffer"(%14) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%12, %15) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %16 = "north_star.get_tensor"(%15) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x6204461b2510) {
  %19 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x6204461f89e0) {
  %20 = "north_star.softmax"(%19) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x6204461f8aa0) {
  "north_star.return"(%20) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x6204461f8bb0) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpConvertPattern"
    ** Insert  : 'north_star.device_kernel'(0x6204461fcd20)
    ** Insert Block into : 'north_star.device_kernel'(0x6204461fcd20)
    ** Insert  : 'north_star.softmax'(0x6204461fb810)
    ** Insert  : 'north_star.softmax'(0x6204461fce00)
    ** Insert  : 'north_star.return'(0x6204461fcb10)
<block argument> of type '!north_star.ns_tensor<1x128xf32,1>' at index: 0
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x6204461fd110)
    ** Replace : 'north_star.device_kernel'(0x6204461f8bb0)
"{anonymous}::DeviceKernelOpConvertPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x6204461fb810) {
      %22 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x6204461c6ea0)
        ** Insert  : 'linalg.softmax'(0x6204461fe320)
        ** Replace : 'north_star.softmax'(0x6204461fb810)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x6204461c6ea0) {
          %23 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x6204461fe320) {
          %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  %2 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  north_star.return %5 : !north_star.ns_tensor<1x128xf32,1>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.device_kernel'(0x6204461fcd20) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x6204461fb810) {
      %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked 'ignored' during conversion
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x6204461fce00) {
      %26 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x6204461fe430)
        ** Insert  : 'linalg.softmax'(0x6204461fe4a0)
        ** Replace : 'north_star.softmax'(0x6204461fce00)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x6204461fe430) {
          %26 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x6204461fe4a0) {
          %27 = "linalg.softmax"(%24, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  %2 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
  %6 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%5 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %7 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  north_star.return %7 : !north_star.ns_tensor<1x128xf32,1>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x6204461fcb10) {
      "north_star.return"(%28) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.return -> ()' {
Trying to match "{anonymous}::ReturnOpConvertPattern"
        ** Insert  : 'north_star.return'(0x6204461fe610)
        ** Replace : 'north_star.return'(0x6204461fcb10)
"{anonymous}::ReturnOpConvertPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'north_star.return'(0x6204461fe610) {
          "north_star.return"(%27) : (tensor<1x128xf32>) -> ()

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'north_star.return' op must be the last operation in the parent block
mlir-asm-printer: 'north_star.device_kernel' failed to verify and will be printed in generic form
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %1 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %2 = "builtin.unrealized_conversion_cast"(%1) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %4 = "linalg.softmax"(%2, %3) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %5 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %6 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %7 = "linalg.softmax"(%4, %6) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %8 = "north_star.softmax"(%5) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  "north_star.return"(%7) : (tensor<1x128xf32>) -> ()
  "north_star.return"(%8) : (!north_star.ns_tensor<1x128xf32,1>) -> ()
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461fd110) {
      %21 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'north_star.return' op must be the last operation in the parent block
'north_star.return' op must be the last operation in the parent block
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
^bb0(%arg0: !north_star.ns_tensor<2x128xf32,0>):
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "builtin.unrealized_conversion_cast"(%6) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %9 = "builtin.unrealized_conversion_cast"(%8) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %10 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg4: tensor<1x128xf32>):
    %31 = "north_star.tensor_to_ns_tensor"(%arg4) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %32 = "builtin.unrealized_conversion_cast"(%31) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %33 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
    %34 = "linalg.softmax"(%32, %33) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %35 = "north_star.softmax"(%31) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %36 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
    %37 = "linalg.softmax"(%34, %36) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %38 = "north_star.softmax"(%35) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    "north_star.return"(%37) : (tensor<1x128xf32>) -> ()
    "north_star.return"(%38) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %11 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg3: !north_star.ns_tensor<1x128xf32,0>):
    %29 = "north_star.softmax"(%arg3) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %30 = "north_star.softmax"(%29) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    "north_star.return"(%30) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %12 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg2: tensor<1x128xf32>):
    %21 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %22 = "builtin.unrealized_conversion_cast"(%21) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %23 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
    %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %26 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
    %27 = "linalg.softmax"(%24, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %28 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    "north_star.return"(%27) : (tensor<1x128xf32>) -> ()
    "north_star.return"(%28) : (!north_star.ns_tensor<1x128xf32,1>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %13 = "north_star.device_kernel"(%8) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %19 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %20 = "north_star.softmax"(%19) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    "north_star.return"(%20) : (!north_star.ns_tensor<1x128xf32,1>) -> ()
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %15 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
  %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x6204461f8cb0) {
  %19 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x6204461f8d40) {
  %20 = "north_star.softmax"(%19) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x6204461f8dc0) {
  "north_star.return"(%20) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x6204461e4d20) {
  %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461f8e50) {
  %15 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461df7f0) {
  %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x6204461f0720) {
  %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.gather'(0x6204461e4ec0) {
  "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x6204461b1fb0) {
  %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::NSTensorToTensorOpGenericAdaptorBase::Properties)
** Insert  : 'north_star.ns_tensor_to_tensor'(0x6204461fd390)
** Insert  : 'north_star.ns_tensor_to_tensor'(0x6204461fd2b0)
** Insert  : 'north_star.ns_tensor_to_tensor'(0x6204461fd8e0)
** Insert  : 'north_star.ns_tensor_to_tensor'(0x6204461fd970)
** Insert  : 'north_star.tensor_to_ns_tensor'(0x6204461fda30)
** Insert  : 'north_star.tensor_to_ns_tensor'(0x6204461fdaf0)
run out: ConvertNorthStarToLinalgPass
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::DestinationStyleOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::AggregatedOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::linalg::AggregatedOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface::Trait<mlir::TypeID::get() [with Trait = mlir::TilingInterface::Trait]::Empty>)
// -----// IR Dump After ConvertNorthStarToLinalgPass (convert-north-satr-to-linalg) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = "north_star.ns_tensor_to_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = "north_star.ns_tensor_to_tensor"(%8) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %10 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %19 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
      %20 = "north_star.ns_tensor_to_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
      %21 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
      %22 = linalg.softmax dimension(1) ins(%20 : tensor<1x128xf32>) outs(%21 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %23 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
      %24 = linalg.softmax dimension(1) ins(%22 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
      north_star.return %24 : tensor<1x128xf32>
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %11 = "north_star.tensor_to_ns_tensor"(%10) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %12 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %19 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
      %20 = "north_star.ns_tensor_to_tensor"(%19) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
      %21 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
      %22 = linalg.softmax dimension(1) ins(%20 : tensor<1x128xf32>) outs(%21 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %23 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
      %24 = linalg.softmax dimension(1) ins(%22 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
      north_star.return %24 : tensor<1x128xf32>
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %15 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %18 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in ConvertNorthStarToFuncPass

//===-------------------------------------------===//
Legalizing operation : 'builtin.module'(0x6204461aef60) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.func'(0x6204461b2bd0) {
} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x6204461f1670) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461e4f90) {
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461f8ec0) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461f97c0) {
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461f9830) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x6204461f98c0) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.scatter'(0x6204461f9960) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x6204461f9a10) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x6204461fd970) {
  %7 = "north_star.ns_tensor_to_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x6204461f9aa0) {
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x6204461fd2b0) {
  %9 = "north_star.ns_tensor_to_tensor"(%8) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x6204461f0ce0) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpToFuncPattern"
    ** Insert  : 'func.call'(0x6204461fb5d0)
    ** Insert Block into : 'func.func'(0x6204461fb650)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x6204461fb810)
    ** Insert  : 'north_star.ns_tensor_to_tensor'(0x6204461f71f0)
    ** Insert  : 'tensor.empty'(0x6204461f6760)
    ** Insert  : 'linalg.softmax'(0x6204461fe5b0)
    ** Insert  : 'tensor.empty'(0x6204461fead0)
    ** Insert  : 'linalg.softmax'(0x6204461f9b30)
    ** Insert  : 'north_star.return'(0x6204461fe540)
    ** Replace : 'north_star.device_kernel'(0x6204461f0ce0)
"{anonymous}::DeviceKernelOpToFuncPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'func.func'(0x6204461fb650) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'func.call'(0x6204461fb5d0) {
      %16 = "func.call"(%13) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 0 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461fb810) {
      %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x6204461f71f0) {
      %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x6204461f6760) {
      %2 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'linalg.softmax'(0x6204461fe5b0) {
      %3 = "linalg.softmax"(%1, %2) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x6204461fead0) {
      %4 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'linalg.softmax'(0x6204461f9b30) {
      %5 = "linalg.softmax"(%3, %4) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x6204461fe540) {
      "north_star.return"(%5) : (tensor<1x128xf32>) -> ()

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.return -> ()' {
Trying to match "{anonymous}::ReturnOpToFuncPattern"
        ** Insert  : 'func.return'(0x6204461fd190)
        ** Replace : 'north_star.return'(0x6204461fe540)
"{anonymous}::ReturnOpToFuncPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'func.return'(0x6204461fd190) {
          "func.return"(%5) : (tensor<1x128xf32>) -> ()

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'func.return' op must be the last operation in the parent block
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (tensor<1x128xf32>) -> tensor<1x128xf32>, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %2 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %3 = "linalg.softmax"(%1, %2) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %5 = "linalg.softmax"(%3, %4) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  "func.return"(%5) : (tensor<1x128xf32>) -> ()
  "north_star.return"(%5) : (tensor<1x128xf32>) -> ()
}) {device_kernel} : () -> ()


    } -> SUCCESS
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "north_star.ns_tensor_to_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %9 = "north_star.ns_tensor_to_tensor"(%8) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %10 = call @softmax_1_128_softmax_1_128_fused_kernel(%7) {device_id = 0 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %11 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %20 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %21 = "north_star.ns_tensor_to_tensor"(%20) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %22 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %23 = linalg.softmax dimension(1) ins(%21 : tensor<1x128xf32>) outs(%22 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %24 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %25 = linalg.softmax dimension(1) ins(%23 : tensor<1x128xf32>) outs(%24 : tensor<1x128xf32>) -> tensor<1x128xf32>
    north_star.return %25 : tensor<1x128xf32>
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %13 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %20 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %21 = "north_star.ns_tensor_to_tensor"(%20) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %22 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %23 = linalg.softmax dimension(1) ins(%21 : tensor<1x128xf32>) outs(%22 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %24 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %25 = linalg.softmax dimension(1) ins(%23 : tensor<1x128xf32>) outs(%24 : tensor<1x128xf32>) -> tensor<1x128xf32>
    north_star.return %25 : tensor<1x128xf32>
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %14 = "north_star.tensor_to_ns_tensor"(%13) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %15 = "north_star.buffer"(%12, %14) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %16 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
  %17 = "north_star.tensor_to_ns_tensor"(%16) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %18 = "north_star.buffer"(%17) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%15, %18) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %19 = "north_star.get_tensor"(%18) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  return %19 : !north_star.ns_tensor<2x128xf32,0>
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461fb780) {
  %32 = "north_star.tensor_to_ns_tensor"(%arg3) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x6204461fd8e0) {
  %33 = "north_star.ns_tensor_to_tensor"(%32) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461fe7c0) {
  %34 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x6204461fe830) {
  %35 = "linalg.softmax"(%33, %34) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461fe9b0) {
  %36 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x6204461fea20) {
  %37 = "linalg.softmax"(%35, %36) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x6204461f73a0) {
  "north_star.return"(%37) : (tensor<1x128xf32>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461fda30) {
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x6204461fcd20) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpToFuncPattern"
    ** Insert  : 'func.call'(0x6204461fe900)
    ** Replace : 'north_star.device_kernel'(0x6204461fcd20)
"{anonymous}::DeviceKernelOpToFuncPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'func.call'(0x6204461fe900) {
      %19 = "func.call"(%15) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 1 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "north_star.ns_tensor_to_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %9 = "north_star.ns_tensor_to_tensor"(%8) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %10 = call @softmax_1_128_softmax_1_128_fused_kernel(%7) {device_id = 0 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %11 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %21 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %22 = "north_star.ns_tensor_to_tensor"(%21) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %23 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %24 = linalg.softmax dimension(1) ins(%22 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %26 = linalg.softmax dimension(1) ins(%24 : tensor<1x128xf32>) outs(%25 : tensor<1x128xf32>) -> tensor<1x128xf32>
    north_star.return %26 : tensor<1x128xf32>
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %13 = call @softmax_1_128_softmax_1_128_fused_kernel(%9) {device_id = 1 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %14 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %21 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %22 = "north_star.ns_tensor_to_tensor"(%21) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %23 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %24 = linalg.softmax dimension(1) ins(%22 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %26 = linalg.softmax dimension(1) ins(%24 : tensor<1x128xf32>) outs(%25 : tensor<1x128xf32>) -> tensor<1x128xf32>
    north_star.return %26 : tensor<1x128xf32>
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %15 = "north_star.tensor_to_ns_tensor"(%14) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %16 = "north_star.buffer"(%12, %15) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %17 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %19 = "north_star.buffer"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%16, %19) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  return %20 : !north_star.ns_tensor<2x128xf32,0>
}


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461fd110) {
  %27 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x6204461fd390) {
  %28 = "north_star.ns_tensor_to_tensor"(%27) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461c6ea0) {
  %29 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x6204461fe320) {
  %30 = "linalg.softmax"(%28, %29) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461fe430) {
  %31 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x6204461fe4a0) {
  %32 = "linalg.softmax"(%30, %31) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x6204461fe610) {
  "north_star.return"(%32) : (tensor<1x128xf32>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461fdaf0) {
  %21 = "north_star.tensor_to_ns_tensor"(%20) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x6204461e4d20) {
  %22 = "north_star.buffer"(%18, %21) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x6204461f8e50) {
  %23 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x6204461df7f0) {
  %24 = "north_star.tensor_to_ns_tensor"(%23) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x6204461f0720) {
  %25 = "north_star.buffer"(%24) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.gather'(0x6204461e4ec0) {
  "north_star.gather"(%22, %25) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x6204461b1fb0) {
  %26 = "north_star.get_tensor"(%25) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.return'(0x6204461b2b50) {
  "func.return"(%26) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//
run out: ConvertNorthStarToFuncPass
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::CallOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::SymbolUserOpInterface::Trait]::Empty>)
// -----// IR Dump After ConvertNorthStarToFuncPass (convert-north-satr-to-func) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = "north_star.ns_tensor_to_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = "north_star.ns_tensor_to_tensor"(%8) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %10 = call @softmax_1_128_softmax_1_128_fused_kernel(%7) {device_id = 0 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %11 = "north_star.tensor_to_ns_tensor"(%10) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %12 = call @softmax_1_128_softmax_1_128_fused_kernel(%9) {device_id = 1 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %15 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %18 : !north_star.ns_tensor<2x128xf32,0>
  }
  func.func @softmax_1_128_softmax_1_128_fused_kernel(%arg0: tensor<1x128xf32>) -> tensor<1x128xf32> attributes {device_kernel} {
    %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %2 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %4 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %5 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%4 : tensor<1x128xf32>) -> tensor<1x128xf32>
    return %5 : tensor<1x128xf32>
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = "north_star.ns_tensor_to_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = "north_star.ns_tensor_to_tensor"(%8) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %10 = call @softmax_1_128_softmax_1_128_fused_kernel(%7) {device_id = 0 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %11 = "north_star.tensor_to_ns_tensor"(%10) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %12 = call @softmax_1_128_softmax_1_128_fused_kernel(%9) {device_id = 1 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %15 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %18 : !north_star.ns_tensor<2x128xf32,0>
  }
  func.func @softmax_1_128_softmax_1_128_fused_kernel(%arg0: tensor<1x128xf32>) -> tensor<1x128xf32> attributes {device_kernel} {
    %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %2 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %4 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %5 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%4 : tensor<1x128xf32>) -> tensor<1x128xf32>
    return %5 : tensor<1x128xf32>
  }
}


initializing north_star
register north_star  Type
register north_star  Attr
register north_star  Op
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = "north_star.ns_tensor_to_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = "north_star.ns_tensor_to_tensor"(%8) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %10 = call @softmax_1_128_softmax_1_128_fused_kernel(%7) {device_id = 0 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %11 = "north_star.tensor_to_ns_tensor"(%10) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %12 = call @softmax_1_128_softmax_1_128_fused_kernel(%9) {device_id = 1 : i64} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %15 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %18 : !north_star.ns_tensor<2x128xf32,0>
  }
  func.func @softmax_1_128_softmax_1_128_fused_kernel(%arg0: tensor<1x128xf32>) -> tensor<1x128xf32> attributes {device_kernel} {
    %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %2 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %4 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %5 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%4 : tensor<1x128xf32>) -> tensor<1x128xf32>
    return %5 : tensor<1x128xf32>
  }
}

destroying north_star
Verifying op: 0x6204461aef60
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461aef60
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461aef60
Verifying op: 0x6204461f0ce0
Verifying op: 0x6204461f0ce0
Verifying op: 0x6204461f0ce0
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461fcd20
Verifying op: 0x6204461fcd20
Verifying op: 0x6204461fcd20
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461aef60
Verifying op: 0x6204461fb650
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461b2bd0
Verifying op: 0x6204461aef60
Verifying op: 0x6204461aef60
Verifying op: 0x6204461aef60
